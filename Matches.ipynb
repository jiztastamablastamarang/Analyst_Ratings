{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_lg\n",
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy import displacy, Language\n",
    "import en_core_web_lg\n",
    "# nlp = en_core_web_lg.load()\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "import nltk\n",
    "from nltk import Tree\n",
    "from nltk import punkt\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "import dateparser\n",
    "import re\n",
    "from currencies import Currency\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nlp = en_core_web_lg.load()\n",
    "tickers = [ #ticker keywords\n",
    "          \"TSMC\", \"Taiwan Semiconductor\", \"\\(TSM\\)\",\n",
    "          \"NVDA\", \"NVIDIA\", \"Nvidia\", \"NVidia\",\n",
    "          \"ASML\", \"Advanced Semiconductor Materials International\",\n",
    "          \"QRVO\", \"Qorvo\",\n",
    "          \"RNECY\", \"Renesas\",\n",
    "          \"ASX\",\n",
    "          \"ATEYY\", \"Advantest\", \"ADVANTEST\",\n",
    "          \"OIIM\", \"O2Micro\",\n",
    "          \"\\(RESN\\)\", \"Resonant\", \"RESONANT\",\n",
    "          \"INTT\", \"inTEST\" , \"inTest\"\n",
    "]\n",
    "keywords = tuple([\"target price\", \"price target\", \"price objective\", \"objective price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Analyst & Organizations from TipRanks\n",
    "path_global = \"g:/My Drive/ETF/\"\n",
    "path = [f\"{path_global}Analysts.xlsx\",\n",
    "        f\"{path_global}Bloggers.xlsx\"]\n",
    "data_a = pd.read_excel(path[0], sheet_name=\"Sheet1\")\n",
    "data_b = pd.read_excel(path[1], sheet_name=\"Sheet1\")\n",
    "#data_b[\"name_\"] = data_b[\"url\"].str.replace(\"/analysts/\", \"\").str.replace(\"-\", \" \")\n",
    "data = pd.concat([data_a, data_b], ignore_index=True)\n",
    "labels = []\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "for names in data[\"name\"].dropna(how='all').unique():\n",
    "    labels.append({\"label\": \"ANALYST\", \"pattern\": [{\"ORTH\": name} for name in [str(token) for token in tokenizer(names)]]})\n",
    "labels.append({\"label\": \"ANALYST\", \"pattern\":\"Analysts\"})\n",
    "labels.append({\"label\": \"ANALYST\", \"pattern\":\"analysts\"})\n",
    "for names in data[\"worksFor\"].dropna(how='all').unique():\n",
    "    labels.append({\"label\": \"ANALYST ORG\", \"pattern\": [{\"ORTH\": name} for name in [str(token) for token in tokenizer(names)]]})\n",
    "\n",
    "# Tickers\n",
    "labels.extend([{\"label\": \"ORG\", \"pattern\": [{\"ORTH\": t} for t in [str(token) for token in tokenizer(ticker)]]} for ticker in tickers])\n",
    "\n",
    "try:\n",
    "  nlp.remove_pipe(name=\"entity_ruler\")\n",
    "except:\n",
    "  pass\n",
    "# ruler = EntityRuler(nlp, overwrite_ents=True)\n",
    "# ruler = nlp.add_pipe(\"entity_ruler\", overwrite_ents=True)\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "# nlp.add_pipe(ruler, before='ner')\n",
    "ruler.add_patterns(list(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add Entities corrector to pipeline\n",
    "class UpdateEntities(object):\n",
    "    def __init__(self, nlp, label, mask, tail):\n",
    "        from spacy.strings import StringStore\n",
    "        if not label in nlp.vocab.strings:\n",
    "          nlp.vocab.strings.add(label)\n",
    "        self.label = nlp.vocab.strings[label]\n",
    "        # self.label = label\n",
    "        self.mask = mask\n",
    "        self.tail = tail\n",
    "    def __call__(self, doc):\n",
    "        import re\n",
    "        from spacy.tokens import Span\n",
    "        if self.tail:\n",
    "          tail_len = len(self.tail)+1\n",
    "        else:\n",
    "          tail_len = 0\n",
    "        matches = [(m.start(), (m.end()-tail_len)) for m in re.finditer(self.mask, doc.text, re.IGNORECASE)] #m.group()\n",
    "        ents = list(doc.ents)\n",
    "        # for ent in ents:\n",
    "        #     if ent.label_ == self.label:\n",
    "        #         bool = True\n",
    "        if matches:\n",
    "          for match in matches:\n",
    "            start, end = match\n",
    "            indx = set()\n",
    "            for i, token in enumerate(doc):\n",
    "              if token.idx == start or (token.idx+len(token)) == end:\n",
    "                # if i==(len(doc)-1):\n",
    "                #   indx.add(i+1)\n",
    "                # else:\n",
    "                  indx.add(i)\n",
    "            entity = Span(doc, min(indx), max(indx)+1, label=self.label)\n",
    "            ents = tuple([ent for ent in ents if ent.start_char not in range(start,end)]) + (entity,)\n",
    "        doc.ents = ents\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<__main__.UpdateEntities at 0x1f80f794880>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyst ORG\n",
    "try:\n",
    "  nlp.remove_pipe(name=\"analyst_org\")\n",
    "except:\n",
    "  pass\n",
    "\n",
    "@Language.factory(\"analyst_org\")\n",
    "def new_component(nlp, name):\n",
    "    return UpdateEntities(nlp, label=\"ANALYST ORG\", mask= r\"^[A-Z][A-Z\\.a-z/]+\\W+analyst\", tail=\"analyst\")\n",
    "# nlp.add_pipe(analyst_org , name=\"analyst_org\", before=\"ner\")\n",
    "nlp.add_pipe(\"analyst_org\", before=\"ner\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%% Currencies\n"
    }
   },
   "outputs": [],
   "source": [
    "from currencies import Currency\n",
    "# CURR = r\"|\".join([key for key in Currency.money_formats])\n",
    "# REG = r\"([A-Z]*\\$\\d+[.,]?\\d*[^., ])|(\\d+[.,]?\\d+\\s?(\" + CURR + \"|yen|euro){1})|((\" + CURR + \"|yen|euro){1}\\s?((\\d)+[.,]?\\d+))|(\\$\\d+)\"\n",
    "#All codes & symbols\n",
    "path_currencies = f\"{path_global}currencies.json\"\n",
    "with open(path_currencies, encoding='utf-8') as file:\n",
    "     symbols = json.load(file)\n",
    "CURR_PREFIX = {key[\"symbol\"] for key in symbols}\n",
    "CURR_SUFFIX = {str(re.findall(r\"\\w+$\", key[\"name\"])[0]).lower() for key in symbols} | {str(re.findall(r\"\\w+$\", key[\"name_plural\"])[0]).lower() for key in symbols}\n",
    "CURR_CODES = {key[\"code\"] for key in symbols}\n",
    "CURR_ALL = \"|\".join(CURR_PREFIX | CURR_SUFFIX | CURR_CODES)\n",
    "\n",
    "# Mask for CURRENCY entity\n",
    "REG = r\"([A-Z]*\\$\\d+[.,]?\\d*[^., ])|(\\d+[.,]?\\d+\\s?(\" + CURR_ALL + \"){1})|((\" + CURR_ALL + \"){1}\\s?((\\d)+[.,]?\\d+))|(\\$\\d+)\"\n",
    "\n",
    "currency_codes = pd.read_json(path_currencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<__main__.UpdateEntities at 0x1f80d99cdc0>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@Language.factory(\"currency\")\n",
    "def new_component(nlp, name):\n",
    "    return UpdateEntities(nlp, label=\"CURRENCY\", mask= REG, tail=None)\n",
    "\n",
    "try:\n",
    "  nlp.remove_pipe(name=\"currency\")\n",
    "except:\n",
    "  pass\n",
    "# nlp.add_pipe(currency, name=\"currency\", before=\"ner\")\n",
    "nlp.add_pipe(\"currency\", before=\"ner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['tok2vec',\n 'tagger',\n 'parser',\n 'attribute_ruler',\n 'lemmatizer',\n 'entity_ruler',\n 'analyst_org',\n 'currency',\n 'ner',\n 'all_rules']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the rules with objects\n",
    "class AllRules(object):\n",
    "    def __init__(self, nlp):\n",
    "        pass\n",
    "    def __call__(self, doc):\n",
    "\n",
    "      # Matcher\n",
    "      labels = (\"RATING\", \"TARGET STRING\", \"ANALYST\",  \"ANALYST ORG\", \"TARGET PRICE\", \"OBJ\", \"VERB\")\n",
    "      ENTITIES = [\"ORG\", \"NORP\", \"OBJ\", \"GPE\", \"LOC\", \"WORK_OF_ART\"]\n",
    "      def add_label(matcher, doc, i, matches):\n",
    "        ents = list(doc.ents)\n",
    "        try:\n",
    "          match_id, start, end = matches[i]\n",
    "          entity = Span(doc, start, end, label=label)\n",
    "          doc.ents += (entity,)\n",
    "        except:\n",
    "            match_id, start, end = matches[i]\n",
    "            for element in [start, end-1]:\n",
    "              for j, ent in enumerate(doc.ents):\n",
    "                #if ent.start_char == doc[element].idx and (ent.label_ not in labels or ent.label_==\"RATING\" and label==\"OLD RATING\"):\n",
    "                  #ents[j] = Span(doc, ents[j].start, ents[j].end, label=label)\n",
    "                if any([item in range(ent.start, ent.end) for item in range(start, end)]) and (ent.label_ not in labels or (ent.label_==\"RATING\" and label==\"OLD RATING\")):\n",
    "                  entity = Span(doc, ent.start, ent.end, label=label)\n",
    "                  ents =  tuple([e for e in ents if e.start != ent.start]) + (entity,)\n",
    "            doc.ents = ents\n",
    "\n",
    "      def add_match(matcher, label, pattern, on_match):\n",
    "          matcher.add(label, pattern, on_match=on_match)\n",
    "\n",
    "\n",
    "      # Simple ratigs\n",
    "      matcher_rating = Matcher(nlp.vocab)\n",
    "      ratings = [\"sell\", \"moderate-sell\", \"underweight\", \"under-weight\", \"hold\", \"holds\", \"neutral\",\n",
    "                \"outperform\", \"moderate-buy\", \"overweight\", \"over-weight\", \"accumulate\", \"add\", \"buy\",\n",
    "                \"strong-buy\", \"bullish\", \"underperform\", \"positive\", \"negative\", \"reduce\"]\n",
    "      pattern = [[{\"ORTH\": '\"'}, {\"LOWER\": rating}, {'ORTH': '\"'}] for rating in ratings] + \\\n",
    "                [[{\"ORTH\": '“'}, {\"LOWER\": rating}, {'ORTH': '”'}] for rating in ratings] + \\\n",
    "                [[{\"ORTH\": 'rating', \"OP\": \"+\"}, {\"LOWER\": rating}] for rating in ratings] + \\\n",
    "                [[{\"LOWER\": rating}, {\"ORTH\": 'rating', \"OP\": \"+\"}] for rating in ratings] + \\\n",
    "                [[{\"ORTH\": rating.title()}] for rating in ratings]\n",
    "      add_match(matcher_rating, \"RATING\", pattern, add_label)\n",
    "\n",
    "      # Complex rating\n",
    "      matcher_phrase = PhraseMatcher(nlp.vocab)\n",
    "      phrases = [\"strong sell\", \"equal weigh\", \"equal weight\", \"moderate sell\", \"strong buy\", \"weak hold\", \"market perform\", \"sector perform\"]\n",
    "      pattern = [nlp.make_doc(phrase) for phrase in phrases] + \\\n",
    "                [nlp.make_doc(phrase.title()) for phrase in phrases]\n",
    "      add_match(matcher_phrase, \"RATING\", pattern, add_label)\n",
    "\n",
    "      # Old rating\n",
    "      matcher_old_rating = Matcher(nlp.vocab)\n",
    "      pattern = [\n",
    "                    [\n",
    "                    {\"TEXT\": \"from\"},\n",
    "                    {\"ENT_TYPE\": \"RATING\"}\n",
    "                    ]\n",
    "                  ]\n",
    "      add_match(matcher_old_rating, \"RATING OLD\", pattern, add_label)\n",
    "\n",
    "      # Target string\n",
    "      matcher_target = PhraseMatcher(nlp.vocab)\n",
    "      prices = [\"target price\", \"price target\", \"price objective\", \"objective price\", \"price targets\"]\n",
    "      pattern = [nlp.make_doc(phrase) for phrase in prices]\n",
    "      add_match(matcher_target, \"TARGET STRING\", pattern, add_label)\n",
    "\n",
    "      # Analyst rematch\n",
    "      matcher_analyst = Matcher(nlp.vocab)\n",
    "      pattern = [\n",
    "                {\"LEMMA\": {\"IN\": [\"analyst\", \"Analyst\"]}}, {\"ENT_TYPE\": \"PERSON\"}\n",
    "      ]\n",
    "      add_match(matcher_analyst, \"ANALYST\", [pattern], add_label)\n",
    "\n",
    "      # Analyst ORG\n",
    "      matcher_analyst_org = Matcher(nlp.vocab)\n",
    "      pattern = [\n",
    "                [\n",
    "                 {\"ENT_TYPE\": {\"IN\": [\"ORG\", \"NORP\", \"OBJ\", \"PERSON\"]}},\n",
    "                {\"LEMMA\": \"analyst\"}\n",
    "                ],\n",
    "                [\n",
    "                 {\"ENT_TYPE\": {\"IN\": [\"ORG\", \"NORP\", \"OBJ\", \"PERSON\",\"GPE\"]}},\n",
    "                 {\"TEXT\": \"analyst\"},\n",
    "                ],\n",
    "                # [\n",
    "                #  {\"POS\": \"NOUN\"},\n",
    "                #  {\"POS\": \"NOUN\", \"OP\": \"*\"},\n",
    "                #  {\"LEMMA\": \"analyst\"}\n",
    "                # ],\n",
    "      ]\n",
    "      add_match(matcher_analyst_org , \"ANALYST ORG\", pattern, add_label)\n",
    "\n",
    "      # Target price\n",
    "      matcher_price = Matcher(nlp.vocab)\n",
    "      pattern = [\n",
    "                [\n",
    "                  {\"TEXT\": \"rating\"},\n",
    "                  {\"TEXT\": \"a\"},\n",
    "                  {\"ENT_TYPE\": \"CURRENCY\"}\n",
    "                ],\n",
    "                [\n",
    "                  {\"ENT_TYPE\": \"TARGET STRING\"},\n",
    "                  {\"POS\": \"ADP\", \"OP\": \"*\"},\n",
    "                  {\"ENT_TYPE\": {\"IN\": [\"ORG\", \"NORP\", \"OBJ\", \"GPE\"]},\"OP\": \"*\" },\n",
    "                  {\"POS\": \"ADP\", \"OP\": \"*\"},\n",
    "                  {\"POS\": \"SYM\", \"OP\": \"*\"},\n",
    "                  {\"ENT_TYPE\": {\"IN\": [\"CURRENCY\", \"MONEY\"]}}\n",
    "                ],\n",
    "                [\n",
    "                  {\"ENT_TYPE\": \"TARGET STRING\"},\n",
    "                  {\"POS\": \"ADP\", \"OP\": \"*\"},\n",
    "                  {\"POS\": \"DET\", \"OP\": \"*\"},\n",
    "                  {\"POS\": \"NOUN\", \"OP\": \"*\"},\n",
    "                  {\"POS\": \"ADP\", \"OP\": \"*\"},\n",
    "                  {\"POS\": \"SYM\", \"OP\": \"*\"},\n",
    "                  {\"ENT_TYPE\": {\"IN\": [\"CURRENCY\", \"MONEY\"]}}\n",
    "                ],\n",
    "                [\n",
    "                  {\"ENT_TYPE\": {\"IN\": ENTITIES}},\n",
    "                  {\"TEXT\": \"shares\"},\n",
    "                  {\"POS\": \"ADP\", \"OP\": \"*\"},\n",
    "                  {\"POS\": \"SYM\", \"OP\": \"*\"},\n",
    "                  {\"ENT_TYPE\": {\"IN\": [\"CURRENCY\"]}}\n",
    "                ],\n",
    "                [\n",
    "                  {\"ENT_TYPE\": {\"IN\": ENTITIES}},\n",
    "                  {\"TEXT\": \"to\"},\n",
    "                  {\"TEXT\": \"a\"},\n",
    "                  {\"ENT_TYPE\": {\"IN\": [\"CURRENCY\"]}}\n",
    "                ],\n",
    "                [\n",
    "                  {\"ENT_TYPE\": {\"IN\": [\"CURRENCY\", \"MONEY\", \"CARDINAL\"]}},\n",
    "                  {\"ENT_TYPE\": \"TARGET STRING\"}\n",
    "                ],\n",
    "                [\n",
    "                  {\"ENT_TYPE\": {\"IN\": [\"RATING\"]}},\n",
    "                  {\"POS\": {\"IN\": [\"NOUN\", \"CCONJ\"]}},\n",
    "                  {\"POS\": {\"IN\": [\"NOUN\", \"CCONJ\"]}},\n",
    "                  {\"ENT_TYPE\": {\"IN\": [\"CURRENCY\"]}}\n",
    "                ],\n",
    "                [\n",
    "                  {\"TEXT\": \"with\"},\n",
    "                  {\"TEXT\": \"a\"},\n",
    "                  {\"ENT_TYPE\": \"CURRENCY\"}\n",
    "                ],\n",
    "                [\n",
    "                  {\"ENT_TYPE\": {\"IN\": [\"CURRENCY\"]}},\n",
    "                  {\"TEXT\": \"from\"}\n",
    "                ],\n",
    "                [\n",
    "                  {\"TEXT\": \"with\"},\n",
    "                  {\"TEXT\": \"a\"},\n",
    "                  {\"ENT_TYPE\": \"CURRENCY\"}\n",
    "                ],\n",
    "                [\n",
    "                  {\"POS\": \"PUNCT\"},\n",
    "                  {\"TEXT\": \"to\"},\n",
    "                  {\"ENT_TYPE\": \"CURRENCY\"}\n",
    "                ],\n",
    "                [\n",
    "                  {\"ENT_TYPE\": \"CURRENCY\"},\n",
    "                  {\"ENT_TYPE\": \"TARGET STRING\"}\n",
    "                ],\n",
    "                [\n",
    "                  {\"ENT_TYPE\": \"RATING\"},\n",
    "                  {\"TEXT\": \"and\"},\n",
    "                  {\"TEXT\": \"a\", \"OP\": \"*\"},\n",
    "                  {\"ENT_TYPE\": \"CURRENCY\"}\n",
    "                ],\n",
    "                [\n",
    "                  {\"ORTH\": \"to\"},\n",
    "                  {\"ENT_TYPE\": \"CURRENCY\"},\n",
    "                  {\"ORTH\": \"from\"}\n",
    "                ],\n",
    "                [\n",
    "                  {\"ENT_TYPE\": \"TARGET STRING\"},\n",
    "                  {\"TEXT\": \"on\"},\n",
    "                  {\"POS\": \"PROPN\"},\n",
    "                  {\"TEXT\": \"to\"},\n",
    "                  {\"ENT_TYPE\": \"CURRENCY\"},\n",
    "                  {\"ORTH\": \"from\", \"OP\": \"*\"}\n",
    "                ],\n",
    "                [\n",
    "                {\"LOWER\": \"street\"},\n",
    "                {\"ORTH\": \"-\"},\n",
    "                {\"ORTH\": \"high\"},\n",
    "                {\"ENT_TYPE\": \"CURRENCY\"},\n",
    "                ],\n",
    "                [\n",
    "                  {\"ENT_TYPE\": \"OBJ\"},\n",
    "                  {\"ORTH\": \"(\", \"OP\": \"*\"},\n",
    "                  {\"ENT_TYPE\": {\"IN\": ENTITIES}, \"OP\": \"*\"},\n",
    "                  {\"ORTH\": \")\", \"OP\": \"*\"},\n",
    "                  {\"ORTH\": \"shares\", \"OP\": \"*\"},\n",
    "                  {\"ORTH\": \"to\"},\n",
    "                  {\"ENT_TYPE\": \"CURRENCY\"},\n",
    "                ],\n",
    "                ]\n",
    "      add_match(matcher_price, \"TARGET PRICE\", pattern, add_label)\n",
    "\n",
    "      # OBJ\n",
    "      matcher_org = Matcher(nlp.vocab)\n",
    "      pattern = [\n",
    "                  [\n",
    "                    {\"ENT_TYPE\": \"TARGET STRING\"},\n",
    "                    {\"POS\": \"ADP\", \"OP\": \"*\"},\n",
    "                    {\"ENT_TYPE\": {\"IN\": ENTITIES}}\n",
    "                  ],\n",
    "                  [\n",
    "                    {\"ENT_TYPE\": \"ANALYST\"},\n",
    "                    {\"POS\": \"VERB\"},\n",
    "                    {\"ENT_TYPE\": {\"IN\": ENTITIES}}\n",
    "                  ],\n",
    "                  [\n",
    "                    {\"ENT_TYPE\": \"TARGET STRING\"},\n",
    "                    {\"POS\": \"ADP\"},\n",
    "                    {\"ENT_TYPE\": {\"IN\": ENTITIES}}\n",
    "                  ],\n",
    "                  [\n",
    "                    {\"ENT_TYPE\": {\"IN\": ENTITIES}},\n",
    "                    {\"POS\": \"ADP\"},\n",
    "                    {\"POS\": \"DET\"},\n",
    "                   {\"ENT_TYPE\": {\"IN\": [\"RATING\", \"OLD RATING\"]}}\n",
    "                  ],\n",
    "                  [\n",
    "                    {\"ENT_TYPE\": \"TARGET STRING\"},\n",
    "                    {\"TEXT\": \"on\"},\n",
    "                    {\"POS\": \"PROPN\"}\n",
    "                  ],\n",
    "                  [\n",
    "                   {\"ENT_TYPE\": \"ANALYST\"},\n",
    "                   {\"POS\": \"VERB\"},\n",
    "                   {\"ENT_TYPE\": {\"IN\": ENTITIES}}\n",
    "                  ],\n",
    "                  [\n",
    "                   {\"POS\": \"PROPN\"},\n",
    "                   {\"POS\": \"ADP\"},\n",
    "                   {\"POS\": \"DET\"},\n",
    "                   {\"ENT_TYPE\": {\"IN\": [\"RATING\", \"OLD RATING\"]}}\n",
    "                  ],\n",
    "                   [\n",
    "                   {\"ENT_TYPE\": {\"IN\": [\"ORG\", \"NORP\", \"PERSON\", \"GPE\", \"LOC\"]}},\n",
    "                   {\"TEXT\": \"with\"},\n",
    "                   {\"TEXT\": \"a\"},\n",
    "                   {\"ENT_TYPE\": \"RATING\"}\n",
    "                  ],\n",
    "                  [\n",
    "                   {\"ENT_TYPE\": \"RATING\"},\n",
    "                   {\"ORTH\": \"-\", \"OP\": \"*\"},\n",
    "                   {\"LOWER\": \"rated\", \"OP\": \"*\"},\n",
    "                   {\"ENT_TYPE\": {\"IN\": ENTITIES}}\n",
    "                 ],\n",
    "                ]\n",
    "      add_match(matcher_org, \"OBJ\", pattern, add_label)\n",
    "\n",
    "      # VERB for ratings\n",
    "      matcher_verb = Matcher(nlp.vocab)\n",
    "      pattern = [\n",
    "                  [\n",
    "                   {\"ENT_TYPE\": {\"IN\": [\"ANALYST\", \"ANALYST ORG\"]}},\n",
    "                   {\"POS\": \"VERB\"},\n",
    "                  ]\n",
    "                ]\n",
    "      def add_label_verb(matcher, doc, i, matches):\n",
    "          match_id, start, end = matches[i]\n",
    "          entity = Span(doc, end-1, end, label=label)\n",
    "          doc.ents += (entity,)\n",
    "\n",
    "      add_match(matcher_verb, \"VERB\", pattern, add_label_verb)\n",
    "\n",
    "      #traing of rules\n",
    "      label = \"RATING\"\n",
    "      matcher_rating(doc)\n",
    "      matcher_phrase(doc)\n",
    "      label = \"OLD RATING\"\n",
    "      matcher_old_rating(doc)\n",
    "      label = \"TARGET STRING\"\n",
    "      matcher_target(doc)\n",
    "      label = \"OBJ\"\n",
    "      matcher_org(doc)\n",
    "      label = \"ANALYST\"\n",
    "      matcher_analyst(doc)\n",
    "      label = \"TARGET PRICE\"\n",
    "      matcher_price(doc)\n",
    "      label = \"ANALYST ORG\"\n",
    "      matcher_analyst_org(doc)\n",
    "      label = \"OBJ\"\n",
    "      matcher_org(doc)\n",
    "      label = \"TARGET PRICE\"\n",
    "      matcher_price(doc)\n",
    "      label = \"VERB\"\n",
    "      matcher_verb(doc)\n",
    "      return doc\n",
    "\n",
    "# Ad to the pipe\n",
    "try:\n",
    "  nlp.remove_pipe(name=\"all_rules\")\n",
    "except:\n",
    "  pass\n",
    "\n",
    "@Language.factory(\"all_rules\")\n",
    "def new_component(nlp, name):\n",
    "    return AllRules(nlp)\n",
    "\n",
    "# nlp.add_pipe(all_rules, name=\"all_rules\", last=True)\n",
    "nlp.add_pipe(\"all_rules\", last=True)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "one = \"\"\"BofA/Merrill analyst Vivek Arya double-upgraded Skyworks (SWKS) and Qorvo (QRVO) to Buy from Underperform, also raising his price targets to $122 from $92 and $130 from $80 respectively.\"\"\"\n",
    "two = \"\"\"Societe Generale started ASML with a Buy rating and 220 euro price target.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Piper Sandler\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ANALYST ORG</span>\n</mark>\n analyst \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Harsh Kumar\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ANALYST</span>\n</mark>\n \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    raised\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">VERB</span>\n</mark>\n the firm's \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    price target\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TARGET STRING</span>\n</mark>\n on \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Nvidia\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">OBJ</span>\n</mark>\n to \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    $220\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TARGET PRICE</span>\n</mark>\n from \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    $172.50\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CURRENCY</span>\n</mark>\n and reiterates an \n<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Overweight\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">RATING</span>\n</mark>\n rating on the shares.</div></span>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = \"Piper Sandler analyst Harsh Kumar raised the firm's price target on Nvidia to $220 from $172.50 and reiterates an Overweight rating on the shares.\"\n",
    "# for element in [\"currency\", \"all_rules\", 'entity_ruler','analyst_org']:\n",
    "#     nlp.disable_pipe(element)\n",
    "doc = nlp(text)\n",
    "# label = \"TEST\"\n",
    "# matcher_test(doc)\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = f\"{path_global}2017-2021/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%% Extract parsed data from headline and sentenize body\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_data(df, column, key):\n",
    "    return df.loc[df[column].str.contains(\"|\".join(key), case=False, regex=True, na=False)].reset_index(drop=True)\n",
    "def relevant_data(data):\n",
    "    dataset = filter_data(data, \"headline\", tickers)\n",
    "    dataset[\"keys\"] = dataset.apply(lambda row: \"; \".join([match.group() for match in re.finditer(\"|\".join(tickers), row[\"headline\"], re.IGNORECASE)]), axis=1)\n",
    "    dataset[\"date\"] = pd.to_datetime(dataset[\"date\"], format=\"%d.%m.%Y\", errors=\"coerce\")\n",
    "    dataset = dataset[dataset[\"date\"] > \"2016-12-31\"]\n",
    "    dataset.dropna(inplace=True)\n",
    "    dataset[\"sentence\"] = dataset.apply(lambda row: sent_tokenize(row[\"body\"])[0], axis=1)\n",
    "    relevant = filter_data(dataset, \"sentence\", [\"price target\", \"target price\"])\n",
    "    relevant[[\"date\", \"URL\", \"headline\", \"body\", \"sentence\", \"keys\"]].to_excel(f\"{path}TheFly_tokenize.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%% Get parsed articles\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset = pd.read_excel(f\"{path}TheFly_tokenize.xlsx\", sheet_name=\"Sheet1\")\n",
    "# dataset[[\"date\", \"headline\", \"sentence\", \"keys\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%% MAIN\n"
    }
   },
   "outputs": [],
   "source": [
    "# COLUMNS = [\"OBJ\", \"ANALYST ORG\", \"ANALYST\", \"RATING\", \"TARGET PRICE\"]\n",
    "# final = pd.DataFrame(columns = dataset.columns.tolist() + COLUMNS)\n",
    "# j=0\n",
    "#\n",
    "# def ent_iteration():\n",
    "#     for ent in doc.ents:\n",
    "#         columns = COLUMNS\n",
    "#         if ent.label_ in columns:\n",
    "#             final.loc[j, ent.label_] = ent\n",
    "#             ENTS.append(ent.label_)\n",
    "#             columns.remove(ent.label_)\n",
    "# #iteration\n",
    "# for i, text in enumerate(dataset[\"sentence\"]):\n",
    "#     doc = nlp(text)\n",
    "#     ENTS = []\n",
    "#     ent_iteration()\n",
    "#     if \"TARGET PRICE\" not in ENTS:\n",
    "#         doc =nlp(text + \" \" + dataset.loc[i,\"headline\"])\n",
    "#         ent_iteration()\n",
    "#     for column in dataset.columns.tolist():\n",
    "#         final.loc[j, column] = dataset.loc[i, column]\n",
    "#     j+=1\n",
    "# final.to_excel(path + \"/ratings.xlsx\")\n",
    "# final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%% CURRENCY CONVERSION\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_currency_code(string):\n",
    "    string = re.sub(r\"[\\d\\., ]\", \"\", string)\n",
    "    code = currency_codes[currency_codes[\"symbol\"]==string][\"code\"]\n",
    "    if code.empty:\n",
    "        return currency_codes[currency_codes[\"name\"].str.contains(string, case=False, regex=True)][\"code\"].values[0]\n",
    "    else:\n",
    "        return code.values[0]\n",
    "\n",
    "\n",
    "def clean_currency(string):\n",
    "    return float(\"\".join(re.findall(r\"[0-9\\.]+\", string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%% Get alalysed data\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "ratings = pd.read_excel(f\"{path_global}ratings - Copy.xlsx\", parse_dates=True)\n",
    "ratings[\"CURRENCY\"] = ratings[\"TARGET PRICE\"]\n",
    "ratings[\"CURRENCY\"] = ratings.apply(lambda row: clean_currency_code(row[\"CURRENCY\"]), axis=1)\n",
    "ratings[\"TARGET PRICE\"] = ratings.apply(lambda row: clean_currency(row[\"TARGET PRICE\"]), axis=1)\n",
    "ratings[\"CURRENCY\"].unique().tolist()\n",
    "ratings.to_excel(f\"{path_global}ratings.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "          date                                         URL  \\\n32  2021-07-12  https://thefly.com/onthefly.php?id=3333101   \n45  2021-06-21  https://thefly.com/onthefly.php?id=3323414   \n86  2021-04-07  https://thefly.com/onthefly.php?id=3278300   \n100 2021-02-24  https://thefly.com/onthefly.php?id=3253445   \n119 2019-07-08  https://thefly.com/onthefly.php?id=2930236   \n..         ...                                         ...   \n648 2021-07-22  https://thefly.com/onthefly.php?id=3340257   \n649 2021-09-24  https://thefly.com/onthefly.php?id=3377271   \n650 2021-09-08  https://thefly.com/onthefly.php?id=3368801   \n653 2020-03-11  https://thefly.com/onthefly.php?id=3049378   \n654 2020-10-12  https://thefly.com/onthefly.php?id=3173581   \n\n                                              headline  \\\n32   Advantest downgraded to Neutral from Buy at Go...   \n45   TSMC downgraded to Equal Weight from Overweigh...   \n86   Advantest downgraded to Buy from Conviction Bu...   \n100  Advantest downgraded to Neutral from Buy at Mi...   \n119      ASML initiated with a Buy at Societe Generale   \n..                                                 ...   \n648  ASML price target raised to EUR 800 from EUR 7...   \n649  ASML price target raised to EUR 800 from EUR 7...   \n650  ASML price target raised to EUR 845 from EUR 6...   \n653  JPMorgan says recession would mean more downsi...   \n654  ASML likely to meet Q3 expectations, says JPMo...   \n\n                                                  body  \\\n32   Goldman Sachs analyst Shuhei Nakamura downgrad...   \n45   On June 18, Morgan Stanley analyst Charlie Cha...   \n86   Goldman Sachs analyst Shuhei Nakamura removed ...   \n100  Mizuho analyst Yoshitsugu Yamamoto downgraded ...   \n119  Societe Generale started ASML with a Buy ratin...   \n..                                                 ...   \n648  Barclays analyst Andrew Gardiner raised the fi...   \n649  Morgan Stanley analyst Dominik Olszewski raise...   \n650  Berenberg analyst Tammy Qiu raised the firm's ...   \n653  JPMorgan analyst Sandeep Deshpande maintained ...   \n654  JPMorgan analyst Sandeep Deshpande reiterated ...   \n\n                                              sentence        OBJ  \\\n32   Goldman Sachs analyst Shuhei Nakamura downgrad...  Advantest   \n45   On June 18, Morgan Stanley analyst Charlie Cha...       TSMC   \n86   Goldman Sachs analyst Shuhei Nakamura removed ...  Advantest   \n100  Mizuho analyst Yoshitsugu Yamamoto downgraded ...  Advantest   \n119  Societe Generale started ASML with a Buy ratin...       ASML   \n..                                                 ...        ...   \n648  Barclays analyst Andrew Gardiner raised the fi...       ASML   \n649  Morgan Stanley analyst Dominik Olszewski raise...       ASML   \n650  Berenberg analyst Tammy Qiu raised the firm's ...       ASML   \n653  JPMorgan analyst Sandeep Deshpande maintained ...       ASML   \n654  JPMorgan analyst Sandeep Deshpande reiterated ...       ASML   \n\n          ANALYST ORG              ANALYST        RATING  TARGET PRICE  \\\n32      Goldman Sachs      Shuhei Nakamura       Neutral     10,000.00   \n45     Morgan Stanley         Charlie Chan  Equal Weight        580.00   \n86      Goldman Sachs      Shuhei Nakamura           Buy     12,500.00   \n100            Mizuho  Yoshitsugu Yamamoto       Neutral     10,000.00   \n119  Societe Generale                  NaN           Buy        220.00   \n..                ...                  ...           ...           ...   \n648          Barclays      Andrew Gardiner    Overweight        800.00   \n649    Morgan Stanley    Dominik Olszewski    Overweight        800.00   \n650         Berenberg            Tammy Qiu           Buy        845.00   \n653          JPMorgan    Sandeep Deshpande    Overweight        280.00   \n654          JPMorgan    Sandeep Deshpande    Overweight        408.00   \n\n    CURRENCY  PRICE  \n32       JPY  90.79  \n45       TWD  20.88  \n86       JPY 113.78  \n100      JPY  94.38  \n119      EUR 246.73  \n..       ...    ...  \n648      EUR 942.00  \n649      EUR 937.52  \n650      EUR 999.38  \n653      EUR 317.41  \n654      EUR 481.40  \n\n[92 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>URL</th>\n      <th>headline</th>\n      <th>body</th>\n      <th>sentence</th>\n      <th>OBJ</th>\n      <th>ANALYST ORG</th>\n      <th>ANALYST</th>\n      <th>RATING</th>\n      <th>TARGET PRICE</th>\n      <th>CURRENCY</th>\n      <th>PRICE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>32</th>\n      <td>2021-07-12</td>\n      <td>https://thefly.com/onthefly.php?id=3333101</td>\n      <td>Advantest downgraded to Neutral from Buy at Go...</td>\n      <td>Goldman Sachs analyst Shuhei Nakamura downgrad...</td>\n      <td>Goldman Sachs analyst Shuhei Nakamura downgrad...</td>\n      <td>Advantest</td>\n      <td>Goldman Sachs</td>\n      <td>Shuhei Nakamura</td>\n      <td>Neutral</td>\n      <td>10,000.00</td>\n      <td>JPY</td>\n      <td>90.79</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>2021-06-21</td>\n      <td>https://thefly.com/onthefly.php?id=3323414</td>\n      <td>TSMC downgraded to Equal Weight from Overweigh...</td>\n      <td>On June 18, Morgan Stanley analyst Charlie Cha...</td>\n      <td>On June 18, Morgan Stanley analyst Charlie Cha...</td>\n      <td>TSMC</td>\n      <td>Morgan Stanley</td>\n      <td>Charlie Chan</td>\n      <td>Equal Weight</td>\n      <td>580.00</td>\n      <td>TWD</td>\n      <td>20.88</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>2021-04-07</td>\n      <td>https://thefly.com/onthefly.php?id=3278300</td>\n      <td>Advantest downgraded to Buy from Conviction Bu...</td>\n      <td>Goldman Sachs analyst Shuhei Nakamura removed ...</td>\n      <td>Goldman Sachs analyst Shuhei Nakamura removed ...</td>\n      <td>Advantest</td>\n      <td>Goldman Sachs</td>\n      <td>Shuhei Nakamura</td>\n      <td>Buy</td>\n      <td>12,500.00</td>\n      <td>JPY</td>\n      <td>113.78</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>2021-02-24</td>\n      <td>https://thefly.com/onthefly.php?id=3253445</td>\n      <td>Advantest downgraded to Neutral from Buy at Mi...</td>\n      <td>Mizuho analyst Yoshitsugu Yamamoto downgraded ...</td>\n      <td>Mizuho analyst Yoshitsugu Yamamoto downgraded ...</td>\n      <td>Advantest</td>\n      <td>Mizuho</td>\n      <td>Yoshitsugu Yamamoto</td>\n      <td>Neutral</td>\n      <td>10,000.00</td>\n      <td>JPY</td>\n      <td>94.38</td>\n    </tr>\n    <tr>\n      <th>119</th>\n      <td>2019-07-08</td>\n      <td>https://thefly.com/onthefly.php?id=2930236</td>\n      <td>ASML initiated with a Buy at Societe Generale</td>\n      <td>Societe Generale started ASML with a Buy ratin...</td>\n      <td>Societe Generale started ASML with a Buy ratin...</td>\n      <td>ASML</td>\n      <td>Societe Generale</td>\n      <td>NaN</td>\n      <td>Buy</td>\n      <td>220.00</td>\n      <td>EUR</td>\n      <td>246.73</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>648</th>\n      <td>2021-07-22</td>\n      <td>https://thefly.com/onthefly.php?id=3340257</td>\n      <td>ASML price target raised to EUR 800 from EUR 7...</td>\n      <td>Barclays analyst Andrew Gardiner raised the fi...</td>\n      <td>Barclays analyst Andrew Gardiner raised the fi...</td>\n      <td>ASML</td>\n      <td>Barclays</td>\n      <td>Andrew Gardiner</td>\n      <td>Overweight</td>\n      <td>800.00</td>\n      <td>EUR</td>\n      <td>942.00</td>\n    </tr>\n    <tr>\n      <th>649</th>\n      <td>2021-09-24</td>\n      <td>https://thefly.com/onthefly.php?id=3377271</td>\n      <td>ASML price target raised to EUR 800 from EUR 7...</td>\n      <td>Morgan Stanley analyst Dominik Olszewski raise...</td>\n      <td>Morgan Stanley analyst Dominik Olszewski raise...</td>\n      <td>ASML</td>\n      <td>Morgan Stanley</td>\n      <td>Dominik Olszewski</td>\n      <td>Overweight</td>\n      <td>800.00</td>\n      <td>EUR</td>\n      <td>937.52</td>\n    </tr>\n    <tr>\n      <th>650</th>\n      <td>2021-09-08</td>\n      <td>https://thefly.com/onthefly.php?id=3368801</td>\n      <td>ASML price target raised to EUR 845 from EUR 6...</td>\n      <td>Berenberg analyst Tammy Qiu raised the firm's ...</td>\n      <td>Berenberg analyst Tammy Qiu raised the firm's ...</td>\n      <td>ASML</td>\n      <td>Berenberg</td>\n      <td>Tammy Qiu</td>\n      <td>Buy</td>\n      <td>845.00</td>\n      <td>EUR</td>\n      <td>999.38</td>\n    </tr>\n    <tr>\n      <th>653</th>\n      <td>2020-03-11</td>\n      <td>https://thefly.com/onthefly.php?id=3049378</td>\n      <td>JPMorgan says recession would mean more downsi...</td>\n      <td>JPMorgan analyst Sandeep Deshpande maintained ...</td>\n      <td>JPMorgan analyst Sandeep Deshpande maintained ...</td>\n      <td>ASML</td>\n      <td>JPMorgan</td>\n      <td>Sandeep Deshpande</td>\n      <td>Overweight</td>\n      <td>280.00</td>\n      <td>EUR</td>\n      <td>317.41</td>\n    </tr>\n    <tr>\n      <th>654</th>\n      <td>2020-10-12</td>\n      <td>https://thefly.com/onthefly.php?id=3173581</td>\n      <td>ASML likely to meet Q3 expectations, says JPMo...</td>\n      <td>JPMorgan analyst Sandeep Deshpande reiterated ...</td>\n      <td>JPMorgan analyst Sandeep Deshpande reiterated ...</td>\n      <td>ASML</td>\n      <td>JPMorgan</td>\n      <td>Sandeep Deshpande</td>\n      <td>Overweight</td>\n      <td>408.00</td>\n      <td>EUR</td>\n      <td>481.40</td>\n    </tr>\n  </tbody>\n</table>\n<p>92 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date, datetime\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "from currency_converter import CurrencyConverter\n",
    "# from forex_python.converter import CurrencyRates\n",
    "converter = CurrencyConverter()\n",
    "PASS= [\"USD\"]\n",
    "for i, price in enumerate(ratings[\"TARGET PRICE\"]):\n",
    "  currency= ratings.loc[i,\"CURRENCY\"]\n",
    "  date = ratings.loc[i,\"date\"]\n",
    "  try:\n",
    "    if currency not in PASS:\n",
    "        ratings.loc[i, \"PRICE\"] = converter.convert(price, currency, 'USD', date=date)\n",
    "    else:\n",
    "        ratings.loc[i,\"PRICE\"] = price\n",
    "  except:\n",
    "    rate = yf.Ticker(f\"{currency}USD=X\").history(period=\"max\")\n",
    "    ratings.loc[i,\"PRICE\"] = rate.loc[date, \"Close\"]*price\n",
    "\n",
    "# ratings.set_index(keys=\"date\", inplace=True)\n",
    "# ratings.to_excel(f\"{path_global}ratings_clean.xlsx\", index=False)\n",
    "ratings[ratings[\"CURRENCY\"]!=\"USD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TICKERS = {\n",
    "          \"TSM\": \"TSMC\",\n",
    "          \"NVDA\":  \"Nvidia\",\n",
    "          \"ASML\": \"ASML\",\n",
    "          \"QRVO\": \"Qorvo\",\n",
    "          \"RNECY\": \"Renesas\",\n",
    "          \"ASX\": \"ASX\",\n",
    "          \"ATEYY\": \"Advantest\",\n",
    "          \"RESN\": \"Resonant\",\n",
    "          \"INTT\": \"inTEST\",\n",
    "          \"OIIM\": \"O2Micro\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%% Rating to number\n"
    }
   },
   "outputs": [],
   "source": [
    "RATINGS_MEANING= {\n",
    "                \"buy\": 1,\n",
    "                \"strong-buy\": 1,\n",
    "                \"moderate-buy\": 1,\n",
    "                \"strong buy\": 1,\n",
    "                \"speculative buy\": 1,\n",
    "                \"overweight\": 1,\n",
    "                \"over-weight\": 1,\n",
    "                \"outperform\": 1,\n",
    "                \"accumulate\": 1,\n",
    "                \"add\": 1,\n",
    "                \"bullish\": 1,\n",
    "                \"positive\": 1,\n",
    "                \"top pick\": 1,\n",
    "                \"focus buy\": 1,\n",
    "                \"action list buy\" : 1,\n",
    "\n",
    "                \"hold\": 0,\n",
    "                \"holds\": 0,\n",
    "                \"neutral\": 0,\n",
    "                \"market perform\": 0,\n",
    "                \"sector perform\":0,\n",
    "                \"peer-preform\": 0,\n",
    "                \"equal weight\": 0,\n",
    "                \"equal weigh\": 0,\n",
    "\n",
    "                \"sell\": -1,\n",
    "                \"negative\": -1,\n",
    "                \"reduce\": -1,\n",
    "                \"strong sell\": -1,\n",
    "                \"moderate-sell\": -1,\n",
    "                \"moderate sell\": -1,\n",
    "                \"underperform\": -1,\n",
    "                \"underweight\": -1,\n",
    "                \"under-weight\": -1,\n",
    "                \"focus reduce\": -1,\n",
    "                \"weak hold\": -1,\n",
    "                \"bearish\": -1,\n",
    "                }\n",
    "# VERBS_RATING =  {\n",
    "#                  'increased': 1,\n",
    "#                  'lowered': -1,\n",
    "#                  'lowers': -1,\n",
    "#                  'raised': 1,\n",
    "#                  # 'reiterated': 0,\n",
    "#                  'removed': -1,\n",
    "#                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings[\"rating\"]=ratings[\"RATING\"].str.lower()\n",
    "ratings  = ratings.replace({\"rating\": RATINGS_MEANING})\n",
    "\n",
    "ratings['buy'] = ratings.apply(lambda x: x[\"PRICE\"] if x[\"rating\"]>0 else (None), axis=1)\n",
    "ratings['sell'] = ratings.apply(lambda x: x[\"PRICE\"] if x[\"rating\"]<0 else (None), axis=1)\n",
    "ratings['hold'] = ratings.apply(lambda x: x[\"PRICE\"] if x[\"rating\"]==0 else (None), axis=1)\n",
    "ratings[\"USD\"] = ratings.apply(lambda x: x[\"PRICE\"] if np.isnan(x[\"rating\"]) else (None), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%% Verb to Rating\n"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# for i, text in enumerate(ratings[\"sentence\"]):\n",
    "#     if np.isnan(ratings.loc[i, \"rating\"]):\n",
    "#         doc = nlp(text)\n",
    "#         verb = [ent.text for ent in doc.ents if ent.label_==\"VERB\"]\n",
    "#         if verb:\n",
    "#             ratings.loc[i, \"rating\"] = verb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ratings.to_excel(f\"{path_global}ratings.xlsx\", index=False)\n",
    "# ratings = ratings.replace({\"rating\": VERBS_RATING})\n",
    "# ratings[\"rating\"].fillna(0, inplace=True)\n",
    "# ratings[\"rating\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%% Vizualization\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-33a8aa324fac>:4: UserWarning: \n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "  import dash_core_components as dcc\n",
      "<ipython-input-23-33a8aa324fac>:6: UserWarning: \n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "  import dash_html_components as html\n"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_html_components as html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app 'Hello World' (lazy loading)\r\n",
      " * Environment: production\r\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\r\n",
      "   Use a production WSGI server instead.\r\n",
      " * Debug mode: off\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "c:\\users\\eugene\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\dash\\resources.py:63: UserWarning: You have set your config to `serve_locally=True` but A local version of https://codepen.io/chriddyp/pen/bWLwgP.css is not available.\n",
      "If you added this file with `app.scripts.append_script` or `app.css.append_css`, use `external_scripts` or `external_stylesheets` instead.\n",
      "See https://dash.plotly.com/external-resources\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [02/Nov/2021 11:14:54] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Nov/2021 11:14:54] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Nov/2021 11:14:54] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Nov/2021 11:14:55] \"GET /_dash-component-suites/dash/dcc/async-dropdown.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Nov/2021 11:14:55] \"GET /_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Nov/2021 11:14:55] \"GET /_dash-component-suites/dash/dcc/async-plotlyjs.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [02/Nov/2021 11:14:55] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from pandas_datareader import data as web\n",
    "\n",
    "app = dash.Dash('Hello World')\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Dropdown(\n",
    "        id='my-dropdown',\n",
    "        options=[\n",
    "            {'label': 'NVIDIA', 'value': 'NVDA'},\n",
    "        ],\n",
    "        value='NVDA'\n",
    "    ),\n",
    "    dcc.Graph(id='my-graph')\n",
    "], style={'width': '500'})\n",
    "\n",
    "@app.callback(Output('my-graph', 'figure'), [Input('my-dropdown', 'value')])\n",
    "def update_graph(selected_dropdown_value):\n",
    "    unit = yf.Ticker(selected_dropdown_value).history (\n",
    "          start=\"2017-01-01\",\n",
    "          end=\"2021-09-30\",\n",
    "          interval='1d')\n",
    "    return {\n",
    "        'data': [{\n",
    "            'x': unit.index,\n",
    "            'y': unit.Close\n",
    "        }],\n",
    "        'layout': {'margin': {'l': 40, 'r': 0, 't': 20, 'b': 30}}\n",
    "    }\n",
    "\n",
    "app.css.append_css({'external_url': 'https://codepen.io/chriddyp/pen/bWLwgP.css'})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ticker = \"TSM\"\n",
    "dataset = ratings[ratings[\"OBJ\"] == TICKERS[ticker]]\n",
    "\n",
    "unit = yf.Ticker(ticker).history (\n",
    "      start=\"2017-01-01\",\n",
    "      end=\"2021-09-30\",\n",
    "      interval='1d')\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=unit.index, y=unit[\"Close\"],))\n",
    "fig.add_trace(go.Scatter(x=dataset.index, y=dataset[\"USD\"], mode=\"markers\"))\n",
    "fig.add_trace(go.Scatter(x=dataset.index, y=dataset[\"buy\"], mode=\"markers\"))\n",
    "fig.add_trace(go.Scatter(x=dataset.index, y=dataset[\"sell\"], mode=\"markers\"))\n",
    "fig.add_trace(go.Scatter(x=dataset.index, y=dataset[\"hold\"], mode=\"markers\"))\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}